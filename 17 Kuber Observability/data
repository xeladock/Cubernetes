kubectl cluster-info dump --all-namespaces --output-directory=cluster-state --output=json

jq '.items[].status.containerStatuses[] | [.image, .state[].startedAt]' cluster-state/default/pods.json

jq '.items[].status.containerStatuses[].image' cluster-state/kube-system/pods.json

POD=$(kubectl get pod  -o jsonpath="{.items[0].metadata.name}")



kubectl exec $POD -- cat entrypoint.sh


kubectl exec -it $POD -- /bin/sh



kubectl exec $POD -- uptime

kubectl exec $POD -- ps

kubectl exec $POD -- stat -f /

kubectl exec $POD --container random-logger -- lsof

kubectl exec $POD --container random-logger -- iostat

kubectl exec $POD --container random-logger -- ls -a -l

export NODE_0=$(kubectl get nodes -o=jsonpath="{.items[0].metadata.name}")

export NODE_1=$(kubectl get nodes -o=jsonpath="{.items[1].metadata.name}")

echo -e "The master node is $NODE_0 \nThe worker node is $NODE_1"

Open a proxy to the Kubernetes API port.

kubectl proxy > /dev/null &

Query the metrics for the master node.

curl localhost:8001/api/v1/nodes/$NODE_0/proxy/metrics

Query the metrics for the worker node.

curl localhost:8001/api/v1/nodes/$NODE_1/proxy/metrics

The Kubernetes API aggregates cluster-wide metrics at /metrics.

curl localhost:8001/metrics/ | jq


helm repo add bitnami https://charts.bitnami.com/bitnami

Install the chart.

helm install metrics-server bitnami/metrics-server \
  --version=4.2.2 \
  --namespace kube-system \
  --set apiService.create=true \
  --set extraArgs.kubelet-insecure-tls=true \
  --set extraArgs.kubelet-preferred-address-types=InternalIP
This will install the server in the kube-system namespace. It also add a new API endpoint named metrics.k8s.io. In a few moments you should be able to list metrics using the following command:

kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes | jq

If the metrics are not ready, this message will appear

Error from server (ServiceUnavailable): the server is currently unable to handle the request

Once the metrics are ready, a JSON dump of the metrics will appear. Additional metrics also appears in the top report.

kubectl top node

If the metrics are not ready you may get this message.

Error from server (ServiceUnavaliable): the server is currently unable to handle the request (get nodes.metrics.k8s.io)

or

error: metrics not available yet

However, once the metrics are available the normal message should look similar to this:

NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
controlplane   138m         6%     991Mi           52%
node01         79m          3%     575Mi           14%
Pod information can also be observed.

kubectl top pods --all-namespaces
